# coding=utf-8
"""
æ¶ˆæ¯å‘é€å™¨æ¨¡å—

å°†æŠ¥å‘Šæ•°æ®å‘é€åˆ°å„ç§é€šçŸ¥æ¸ é“ï¼š
- é£ä¹¦ (Feishu/Lark)
- é’‰é’‰ (DingTalk)
- ä¼ä¸šå¾®ä¿¡ (WeCom/WeWork)
- Telegram
- é‚®ä»¶ (Email)
- ntfy
- Bark
- Slack

æ¯ä¸ªå‘é€å‡½æ•°éƒ½æ”¯æŒåˆ†æ‰¹å‘é€ï¼Œå¹¶é€šè¿‡å‚æ•°åŒ–é…ç½®å®ç°ä¸ CONFIG çš„è§£è€¦ã€‚
"""

import smtplib
import time
from datetime import datetime
from email.header import Header
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.utils import formataddr, formatdate, make_msgid
from pathlib import Path
from typing import Callable, Dict, List, Optional
from urllib.parse import urlparse

import requests

from .batch import add_batch_headers, get_max_batch_header_size
from .formatters import convert_markdown_to_mrkdwn, strip_markdown


# ==========================
# Feishu å¡ç‰‡æ„å»ºï¼ˆå¯å¤ç”¨/å¯é¢„è§ˆï¼‰
# ==========================
def _truncate_text(text: str, max_chars: int) -> str:
    """æˆªæ–­æ–‡æœ¬ï¼Œé¿å…å¡ç‰‡è¿‡å¤§ï¼ˆæŒ‰å­—ç¬¦ç²—ç•¥æ§åˆ¶ï¼‰"""
    if not text:
        return ""
    text = text.strip()
    if max_chars <= 0:
        return ""
    return text if len(text) <= max_chars else (text[:max_chars] + "â€¦")


def build_feishu_card_payload(
    *,
    report_type: str,
    batch_content: str,
    podcast_data: Optional[Dict[str, Dict]] = None,
    include_podcast_sections: bool = False,
    include_podcast_summaries: bool = False,
    include_podcast_buttons: bool = True,
    max_summary_chars_per_keyword: int = 600,
    max_keywords_in_card: int = 10,
) -> Dict:
    """
    æ„å»ºé£ä¹¦ interactive å¡ç‰‡ payloadï¼ˆä¸å‘é€ç½‘ç»œè¯·æ±‚ï¼Œä¾¿äºæœ¬åœ°é¢„è§ˆï¼‰

    Args:
        report_type: æŠ¥å‘Šç±»å‹ï¼ˆå¡ç‰‡æ ‡é¢˜ï¼‰
        batch_content: æœ¬æ‰¹æ¬¡æ­£æ–‡ï¼ˆçƒ­ç‚¹ç»Ÿè®¡/æ–°å¢æ–°é—»ç­‰ï¼‰
        podcast_data: æ’­å®¢æ•°æ® {å…³é”®è¯: {audio_url, summary, article_count}}
        include_podcast_sections: æ˜¯å¦åœ¨å¡ç‰‡æœ«å°¾è¿½åŠ æ’­å®¢ä¸¤æ®µå†…å®¹
        include_podcast_summaries: æ˜¯å¦è¿½åŠ â€œAIæ€»ç»“æ–‡ç¨¿â€åŒºåŸŸï¼ˆå†…å®¹è¾ƒé•¿ï¼Œå¯èƒ½å¯¼è‡´å¡ç‰‡è¿‡å¤§ï¼‰
        include_podcast_buttons: æ˜¯å¦è¿½åŠ â€œæ”¶å¬æ’­å®¢æŒ‰é’®â€åŒºåŸŸï¼ˆæ›´è½»é‡ï¼Œæ¨èå¼€å¯ï¼‰
        max_summary_chars_per_keyword: æ¯ä¸ªå…³é”®è¯æ‘˜è¦çš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆé¿å…å¡ç‰‡è¿‡å¤§ï¼‰
        max_keywords_in_card: æœ€å¤šå±•ç¤ºå¤šå°‘ä¸ªå…³é”®è¯ï¼ˆé¿å…æŒ‰é’®/æ‘˜è¦è¿‡å¤šï¼‰

    Returns:
        é£ä¹¦ webhook æ‰€éœ€çš„ JSON payloadï¼ˆdictï¼‰
    """
    # ä½¿ç”¨æ¶ˆæ¯å¡ç‰‡æ ¼å¼ï¼ˆinteractiveï¼‰ï¼Œæ”¯æŒ <font color='xxx'> ç­‰å¯Œæ–‡æœ¬æ ·å¼
    elements = [{"tag": "markdown", "content": batch_content}]

    if include_podcast_sections and podcast_data:
        # åªä¿ç•™æœ‰å†…å®¹çš„æ¡ç›®ï¼Œå¹¶é™åˆ¶æ•°é‡
        items = []
        for keyword, data in podcast_data.items():
            if not keyword or not isinstance(data, dict):
                continue
            audio_url = (data.get("audio_url") or "").strip()
            summary = (data.get("summary") or "").strip()
            article_count = data.get("article_count", 0) or 0
            # æ—¢æ²¡æœ‰é“¾æ¥ä¹Ÿæ²¡æœ‰æ‘˜è¦ï¼Œå°±æ²¡å¿…è¦å±•ç¤º
            if not audio_url and not summary:
                continue
            items.append((keyword, audio_url, summary, article_count))

        if items:
            items = items[: max_keywords_in_card if max_keywords_in_card > 0 else len(items)]

            # åˆ†éš”çº¿
            elements.append({"tag": "hr"})

            # ç¬¬ä¸€éƒ¨åˆ†ï¼šæ’­å®¢æ”¶å¬æŒ‰é’®ï¼ˆè½»é‡ï¼Œä¼˜å…ˆå±•ç¤ºï¼‰
            if include_podcast_buttons:
                elements.append(
                    {
                        "tag": "markdown",
                        "content": "ğŸ™ï¸ **çƒ­ç‚¹æ’­å®¢**ï¼ˆç‚¹æŒ‰é’®æ”¶å¬ï¼‰",
                    }
                )

                podcast_buttons = []
                for keyword, audio_url, _, __ in items:
                    if not audio_url:
                        continue
                    # æŒ‰é’®æ–‡æ¡ˆä¸ç”¨æˆ·æˆªå›¾ä¿æŒä¸€è‡´ï¼šæ”¶å¬ã€Œxxxã€æ’­å®¢
                    podcast_buttons.append(
                        {
                            "tag": "button",
                            "text": {
                                "tag": "plain_text",
                                "content": f"æ”¶å¬ã€Œ{keyword}ã€æ’­å®¢",
                            },
                            "type": "primary",
                            "multi_url": {
                                "url": audio_url,
                                "pc_url": audio_url,
                                "android_url": audio_url,
                                "ios_url": audio_url,
                            },
                        }
                    )

                # æ¯è¡Œæœ€å¤š 3 ä¸ªæŒ‰é’®ï¼Œåˆ†ç»„æ·»åŠ 
                for j in range(0, len(podcast_buttons), 3):
                    elements.append({"tag": "action", "actions": podcast_buttons[j : j + 3]})

                # å¦‚æœæ²¡æœ‰ä»»ä½•å¯ç”¨é“¾æ¥ï¼Œç»™å‡ºæç¤ºï¼Œé¿å…ç”¨æˆ·è¯¯ä»¥ä¸ºåŠŸèƒ½â€œæ¶ˆå¤±â€
                if not podcast_buttons:
                    elements.append(
                        {
                            "tag": "note",
                            "elements": [
                                {
                                    "tag": "plain_text",
                                    "content": "âš ï¸ æœ¬æ¬¡æœªç”Ÿæˆå¯æ”¶å¬çš„æ’­å®¢é“¾æ¥ï¼ˆè¯·æ£€æŸ¥æ’­å®¢é…ç½®/å¯†é’¥/ä¸Šä¼ å­˜å‚¨ï¼‰",
                                }
                            ],
                        }
                    )

                # åº•éƒ¨è¯´æ˜ï¼ˆä½ çš„æ’­å®¢ä¸Šä¼ é€»è¾‘é‡Œé»˜è®¤ 24h ä¸´æ—¶é“¾æ¥ï¼‰
                elements.append(
                    {
                        "tag": "note",
                        "elements": [
                            {"tag": "plain_text", "content": "ğŸ’¡ éŸ³é¢‘é“¾æ¥é€šå¸¸24å°æ—¶å†…æœ‰æ•ˆ"},
                        ],
                    }
                )

            # ç¬¬äºŒéƒ¨åˆ†ï¼šAI æ–‡ç¨¿æ‘˜è¦ï¼ˆè¾ƒé•¿ï¼Œé»˜è®¤ä¸å±•ç¤ºï¼›ä»…åœ¨éœ€è¦æ—¶å¼€å¯ï¼‰
            if include_podcast_summaries:
                elements.append({"tag": "hr"})
                elements.append(
                    {
                        "tag": "markdown",
                        "content": "ğŸ“ **AIæ€»ç»“æ–‡ç¨¿**ï¼ˆå¯ç›´æ¥é˜…è¯»/è½¬å‘ï¼‰",
                    }
                )

                for keyword, audio_url, summary, article_count in items:
                    summary_preview = _truncate_text(summary, max_summary_chars_per_keyword)
                    header = f"**ğŸ“Œ {keyword}**"
                    if article_count:
                        header += f"ï¼ˆ{article_count} ç¯‡ï¼‰"

                    link_line = f"\n\n[ğŸ§ è¯­éŸ³æ’­å®¢é“¾æ¥]({audio_url})" if audio_url else ""
                    body = f"{header}\n\n{summary_preview}{link_line}"
                    elements.append({"tag": "markdown", "content": body})

    return {
        "msg_type": "interactive",
        "card": {
            "config": {
                "wide_screen_mode": True,
                "enable_forward": True,
            },
            "header": {
                "title": {"tag": "plain_text", "content": f"ğŸ“Š TrendRadar - {report_type}"},
                "template": "blue",
            },
            "elements": elements,
        },
    }


# === SMTP é‚®ä»¶é…ç½® ===
SMTP_CONFIGS = {
    # Gmailï¼ˆä½¿ç”¨ STARTTLSï¼‰
    "gmail.com": {"server": "smtp.gmail.com", "port": 587, "encryption": "TLS"},
    # QQé‚®ç®±ï¼ˆä½¿ç”¨ SSLï¼Œæ›´ç¨³å®šï¼‰
    "qq.com": {"server": "smtp.qq.com", "port": 465, "encryption": "SSL"},
    # Outlookï¼ˆä½¿ç”¨ STARTTLSï¼‰
    "outlook.com": {"server": "smtp-mail.outlook.com", "port": 587, "encryption": "TLS"},
    "hotmail.com": {"server": "smtp-mail.outlook.com", "port": 587, "encryption": "TLS"},
    "live.com": {"server": "smtp-mail.outlook.com", "port": 587, "encryption": "TLS"},
    # ç½‘æ˜“é‚®ç®±ï¼ˆä½¿ç”¨ SSLï¼Œæ›´ç¨³å®šï¼‰
    "163.com": {"server": "smtp.163.com", "port": 465, "encryption": "SSL"},
    "126.com": {"server": "smtp.126.com", "port": 465, "encryption": "SSL"},
    # æ–°æµªé‚®ç®±ï¼ˆä½¿ç”¨ SSLï¼‰
    "sina.com": {"server": "smtp.sina.com", "port": 465, "encryption": "SSL"},
    # æœç‹é‚®ç®±ï¼ˆä½¿ç”¨ SSLï¼‰
    "sohu.com": {"server": "smtp.sohu.com", "port": 465, "encryption": "SSL"},
    # å¤©ç¿¼é‚®ç®±ï¼ˆä½¿ç”¨ SSLï¼‰
    "189.cn": {"server": "smtp.189.cn", "port": 465, "encryption": "SSL"},
    # é˜¿é‡Œäº‘é‚®ç®±ï¼ˆä½¿ç”¨ TLSï¼‰
    "aliyun.com": {"server": "smtp.aliyun.com", "port": 465, "encryption": "TLS"},
}


def send_to_feishu(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 29000,
    batch_interval: float = 1.0,
    split_content_func: Callable = None,
    get_time_func: Callable = None,
    podcast_data: Optional[Dict[str, Dict]] = None,
) -> bool:
    """
    å‘é€åˆ°é£ä¹¦ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä½¿ç”¨æ¶ˆæ¯å¡ç‰‡æ ¼å¼ä»¥æ”¯æŒå¯Œæ–‡æœ¬æ ·å¼ï¼‰

    Args:
        webhook_url: é£ä¹¦ Webhook URL
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        batch_interval: æ‰¹æ¬¡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°
        get_time_func: è·å–å½“å‰æ—¶é—´çš„å‡½æ•°
        podcast_data: æ’­å®¢æ•°æ® {å…³é”®è¯: {audio_url, summary, article_count}}ï¼ˆå¯é€‰ï¼‰

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"é£ä¹¦{account_label}" if account_label else "é£ä¹¦"

    # é¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´ï¼Œé¿å…æ·»åŠ å¤´éƒ¨åè¶…é™
    header_reserve = get_max_batch_header_size("feishu")
    batches = split_content_func(
        report_data,
        "feishu",
        update_info,
        max_bytes=batch_size - header_reserve,
        mode=mode,
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "feishu", batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        content_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        total_titles = sum(
            len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
        )
        now = get_time_func() if get_time_func else datetime.now()

        # é£ä¹¦æ¶ˆæ¯å¯èƒ½ä¼šè¢«åˆ†æ‰¹å‘é€ï¼š
        # - ä¸ºäº†è®©â€œæ’­å®¢æŒ‰é’®â€æ›´å®¹æ˜“è¢«çœ‹åˆ°ï¼šé»˜è®¤æ”¾åœ¨**ç¬¬ä¸€æ‰¹**ï¼ˆè½»é‡ï¼‰
        # - å¦‚æœåªæœ‰ 1 æ‰¹ï¼Œåˆ™å¯åŒæ—¶å±•ç¤ºæŒ‰é’® + AIæ–‡ç¨¿ï¼ˆå¦‚éœ€è¦ï¼‰
        is_first_batch = i == 1
        is_last_batch = i == len(batches)

        payload = build_feishu_card_payload(
            report_type=report_type,
            batch_content=batch_content,
            podcast_data=podcast_data,
            include_podcast_sections=bool(is_first_batch or (is_last_batch and len(batches) == 1)),
            # åªå±•ç¤ºæŒ‰é’®ï¼Œé¿å…å¡ç‰‡è¿‡å¤§å¯¼è‡´å‘é€å¤±è´¥
            include_podcast_buttons=True,
            include_podcast_summaries=False,
            # è¿™é‡Œçš„å€¼æ˜¯â€œä¿å®ˆé…ç½®â€ï¼Œé¿å…é£ä¹¦å¡ç‰‡è¿‡å¤§å¯¼è‡´å‘é€å¤±è´¥
            max_summary_chars_per_keyword=600,
            max_keywords_in_card=10,
        )

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                # æ£€æŸ¥é£ä¹¦çš„å“åº”çŠ¶æ€
                if result.get("StatusCode") == 0 or result.get("code") == 0:
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(batch_interval)
                else:
                    error_msg = result.get("msg") or result.get("StatusMessage", "æœªçŸ¥é”™è¯¯")
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{error_msg}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_podcast_to_feishu(
    webhook_url: str,
    podcast_data: Dict[str, Dict],
    proxy_url: Optional[str] = None,
    account_label: str = "",
) -> bool:
    """
    å‘é€æ’­å®¢éŸ³é¢‘åˆ°é£ä¹¦ï¼ˆä½¿ç”¨æ¶ˆæ¯å¡ç‰‡æ ¼å¼ï¼Œç‚¹å‡»æŒ‰é’®æ”¶å¬ï¼‰
    
    é£ä¹¦ Webhook ä¸æ”¯æŒ audio å…ƒç´ ï¼Œä½¿ç”¨æŒ‰é’®è·³è½¬åˆ°éŸ³é¢‘é“¾æ¥çš„æ–¹å¼ã€‚
    ç”¨æˆ·ç‚¹å‡»æŒ‰é’®ååœ¨æµè§ˆå™¨ä¸­æ’­æ”¾éŸ³é¢‘ã€‚
    
    Args:
        webhook_url: é£ä¹¦ Webhook URL
        podcast_data: æ’­å®¢æ•°æ®å­—å…¸ï¼Œæ ¼å¼ä¸º {å…³é”®è¯: {summary, audio_url, article_count}}
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        
    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    if not podcast_data:
        print("æ²¡æœ‰æ’­å®¢æ•°æ®ï¼Œè·³è¿‡é£ä¹¦æ’­å®¢æ¨é€")
        return False
    
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}
    
    # æ—¥å¿—å‰ç¼€
    log_prefix = f"é£ä¹¦æ’­å®¢{account_label}" if account_label else "é£ä¹¦æ’­å®¢"
    
    # æ„å»ºå¡ç‰‡å…ƒç´ åˆ—è¡¨
    elements = []
    
    # æ·»åŠ æ ‡é¢˜è¯´æ˜
    elements.append({
        "tag": "markdown",
        "content": "ğŸ™ï¸ **çƒ­ç‚¹æ–°é—»æ’­å®¢** - ç‚¹å‡»æŒ‰é’®æ”¶å¬ AI ç”Ÿæˆçš„æ–°é—»æ‘˜è¦\n"
    })
    
    # æ·»åŠ åˆ†éš”çº¿
    elements.append({"tag": "hr"})
    
    # ä¸ºæ¯ä¸ªå…³é”®è¯æ·»åŠ æ’­å®¢å†…å®¹
    for keyword, data in podcast_data.items():
        audio_url = data.get("audio_url", "")
        summary = data.get("summary", "")
        article_count = data.get("article_count", 0)
        
        if not audio_url:
            continue
        
        # æ·»åŠ å…³é”®è¯æ ‡é¢˜å’Œæ‘˜è¦
        keyword_content = f"**ğŸ“Œ {keyword}**"
        if article_count:
            keyword_content += f" ({article_count} ç¯‡ç›¸å…³æŠ¥é“)"
        keyword_content += "\n\n"
        
        if summary:
            # æˆªå–æ‘˜è¦å‰ 150 å­—
            summary_preview = summary[:150] + "..." if len(summary) > 150 else summary
            keyword_content += f"<font color='grey'>{summary_preview}</font>"
        
        elements.append({
            "tag": "markdown",
            "content": keyword_content
        })
        
        # æ·»åŠ æ”¶å¬æŒ‰é’®ï¼ˆè·³è½¬åˆ°éŸ³é¢‘é“¾æ¥ï¼‰
        elements.append({
            "tag": "action",
            "actions": [
                {
                    "tag": "button",
                    "text": {
                        "tag": "plain_text",
                        "content": f"ğŸ§ æ”¶å¬ã€Œ{keyword}ã€æ’­å®¢"
                    },
                    "type": "primary",
                    "multi_url": {
                        "url": audio_url,
                        "pc_url": audio_url,
                        "android_url": audio_url,
                        "ios_url": audio_url
                    }
                }
            ]
        })
        
        # æ·»åŠ åˆ†éš”çº¿
        elements.append({"tag": "hr"})
    
    # ç§»é™¤æœ€åä¸€ä¸ªåˆ†éš”çº¿ï¼Œæ¢æˆåº•éƒ¨è¯´æ˜
    if elements and elements[-1].get("tag") == "hr":
        elements.pop()
    
    # æ·»åŠ åº•éƒ¨è¯´æ˜
    elements.append({
        "tag": "note",
        "elements": [
            {
                "tag": "plain_text",
                "content": "ğŸ¤– ç”± TrendRadar è‡ªåŠ¨ç”Ÿæˆ | éŸ³é¢‘é“¾æ¥ 24 å°æ—¶å†…æœ‰æ•ˆ"
            }
        ]
    })
    
    # æ„å»ºå®Œæ•´çš„å¡ç‰‡æ¶ˆæ¯
    payload = {
        "msg_type": "interactive",
        "card": {
            "config": {
                "wide_screen_mode": True,
                "enable_forward": True,
            },
            "header": {
                "title": {
                    "tag": "plain_text",
                    "content": "ğŸ™ï¸ TrendRadar çƒ­ç‚¹æ’­å®¢"
                },
                "template": "purple"  # ä½¿ç”¨ç´«è‰²ä¸»é¢˜åŒºåˆ†æ™®é€šæ¶ˆæ¯
            },
            "elements": elements
        }
    }
    
    try:
        response = requests.post(
            webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get("StatusCode") == 0 or result.get("code") == 0:
                print(f"{log_prefix}å‘é€æˆåŠŸï¼ŒåŒ…å« {len(podcast_data)} ä¸ªæ’­å®¢")
                return True
            else:
                error_msg = result.get("msg") or result.get("StatusMessage", "æœªçŸ¥é”™è¯¯")
                print(f"{log_prefix}å‘é€å¤±è´¥ï¼š{error_msg}")
                return False
        else:
            print(f"{log_prefix}å‘é€å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
            return False
            
    except Exception as e:
        print(f"{log_prefix}å‘é€å‡ºé”™ï¼š{e}")
        return False


def send_to_dingtalk(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 20000,
    batch_interval: float = 1.0,
    split_content_func: Callable = None,
) -> bool:
    """
    å‘é€åˆ°é’‰é’‰ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰

    Args:
        webhook_url: é’‰é’‰ Webhook URL
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        batch_interval: æ‰¹æ¬¡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"é’‰é’‰{account_label}" if account_label else "é’‰é’‰"

    # é¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´ï¼Œé¿å…æ·»åŠ å¤´éƒ¨åè¶…é™
    header_reserve = get_max_batch_header_size("dingtalk")
    batches = split_content_func(
        report_data,
        "dingtalk",
        update_info,
        max_bytes=batch_size - header_reserve,
        mode=mode,
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "dingtalk", batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        content_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        payload = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type}",
                "text": batch_content,
            },
        }

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(batch_interval)
                else:
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_wework(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 4000,
    batch_interval: float = 1.0,
    msg_type: str = "markdown",
    split_content_func: Callable = None,
) -> bool:
    """
    å‘é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œæ”¯æŒ markdown å’Œ text ä¸¤ç§æ ¼å¼ï¼‰

    Args:
        webhook_url: ä¼ä¸šå¾®ä¿¡ Webhook URL
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        batch_interval: æ‰¹æ¬¡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        msg_type: æ¶ˆæ¯ç±»å‹ (markdown/text)
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"ä¼ä¸šå¾®ä¿¡{account_label}" if account_label else "ä¼ä¸šå¾®ä¿¡"

    # è·å–æ¶ˆæ¯ç±»å‹é…ç½®ï¼ˆmarkdown æˆ– textï¼‰
    is_text_mode = msg_type.lower() == "text"

    if is_text_mode:
        print(f"{log_prefix}ä½¿ç”¨ text æ ¼å¼ï¼ˆä¸ªäººå¾®ä¿¡æ¨¡å¼ï¼‰[{report_type}]")
    else:
        print(f"{log_prefix}ä½¿ç”¨ markdown æ ¼å¼ï¼ˆç¾¤æœºå™¨äººæ¨¡å¼ï¼‰[{report_type}]")

    # text æ¨¡å¼ä½¿ç”¨ wework_textï¼Œmarkdown æ¨¡å¼ä½¿ç”¨ wework
    header_format_type = "wework_text" if is_text_mode else "wework"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    header_reserve = get_max_batch_header_size(header_format_type)
    batches = split_content_func(
        report_data, "wework", update_info, max_bytes=batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, header_format_type, batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        # æ ¹æ®æ¶ˆæ¯ç±»å‹æ„å»º payload
        if is_text_mode:
            # text æ ¼å¼ï¼šå»é™¤ markdown è¯­æ³•
            plain_content = strip_markdown(batch_content)
            payload = {"msgtype": "text", "text": {"content": plain_content}}
            content_size = len(plain_content.encode("utf-8"))
        else:
            # markdown æ ¼å¼ï¼šä¿æŒåŸæ ·
            payload = {"msgtype": "markdown", "markdown": {"content": batch_content}}
            content_size = len(batch_content.encode("utf-8"))

        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(batch_interval)
                else:
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_telegram(
    bot_token: str,
    chat_id: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 4000,
    batch_interval: float = 1.0,
    split_content_func: Callable = None,
) -> bool:
    """
    å‘é€åˆ° Telegramï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰

    Args:
        bot_token: Telegram Bot Token
        chat_id: Telegram Chat ID
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        batch_interval: æ‰¹æ¬¡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    headers = {"Content-Type": "application/json"}
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"Telegram{account_label}" if account_label else "Telegram"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    header_reserve = get_max_batch_header_size("telegram")
    batches = split_content_func(
        report_data, "telegram", update_info, max_bytes=batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "telegram", batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        content_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        payload = {
            "chat_id": chat_id,
            "text": batch_content,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }

        try:
            response = requests.post(
                url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("ok"):
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(batch_interval)
                else:
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('description')}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_email(
    from_email: str,
    password: str,
    to_email: str,
    report_type: str,
    html_file_path: str,
    custom_smtp_server: Optional[str] = None,
    custom_smtp_port: Optional[int] = None,
    *,
    get_time_func: Callable = None,
) -> bool:
    """
    å‘é€é‚®ä»¶é€šçŸ¥

    Args:
        from_email: å‘ä»¶äººé‚®ç®±
        password: é‚®ç®±å¯†ç /æˆæƒç 
        to_email: æ”¶ä»¶äººé‚®ç®±ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰
        report_type: æŠ¥å‘Šç±»å‹
        html_file_path: HTML æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        custom_smtp_server: è‡ªå®šä¹‰ SMTP æœåŠ¡å™¨ï¼ˆå¯é€‰ï¼‰
        custom_smtp_port: è‡ªå®šä¹‰ SMTP ç«¯å£ï¼ˆå¯é€‰ï¼‰
        get_time_func: è·å–å½“å‰æ—¶é—´çš„å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    try:
        if not html_file_path or not Path(html_file_path).exists():
            print(f"é”™è¯¯ï¼šHTMLæ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæä¾›: {html_file_path}")
            return False

        print(f"ä½¿ç”¨HTMLæ–‡ä»¶: {html_file_path}")
        with open(html_file_path, "r", encoding="utf-8") as f:
            html_content = f.read()

        domain = from_email.split("@")[-1].lower()

        if custom_smtp_server and custom_smtp_port:
            # ä½¿ç”¨è‡ªå®šä¹‰ SMTP é…ç½®
            smtp_server = custom_smtp_server
            smtp_port = int(custom_smtp_port)
            # æ ¹æ®ç«¯å£åˆ¤æ–­åŠ å¯†æ–¹å¼ï¼š465=SSL, 587=TLS
            if smtp_port == 465:
                use_tls = False  # SSL æ¨¡å¼ï¼ˆSMTP_SSLï¼‰
            elif smtp_port == 587:
                use_tls = True  # TLS æ¨¡å¼ï¼ˆSTARTTLSï¼‰
            else:
                # å…¶ä»–ç«¯å£ä¼˜å…ˆå°è¯• TLSï¼ˆæ›´å®‰å…¨ï¼Œæ›´å¹¿æ³›æ”¯æŒï¼‰
                use_tls = True
        elif domain in SMTP_CONFIGS:
            # ä½¿ç”¨é¢„è®¾é…ç½®
            config = SMTP_CONFIGS[domain]
            smtp_server = config["server"]
            smtp_port = config["port"]
            use_tls = config["encryption"] == "TLS"
        else:
            print(f"æœªè¯†åˆ«çš„é‚®ç®±æœåŠ¡å•†: {domain}ï¼Œä½¿ç”¨é€šç”¨ SMTP é…ç½®")
            smtp_server = f"smtp.{domain}"
            smtp_port = 587
            use_tls = True

        msg = MIMEMultipart("alternative")

        # ä¸¥æ ¼æŒ‰ç…§ RFC æ ‡å‡†è®¾ç½® From header
        sender_name = "TrendRadar"
        msg["From"] = formataddr((sender_name, from_email))

        # è®¾ç½®æ”¶ä»¶äºº
        recipients = [addr.strip() for addr in to_email.split(",")]
        if len(recipients) == 1:
            msg["To"] = recipients[0]
        else:
            msg["To"] = ", ".join(recipients)

        # è®¾ç½®é‚®ä»¶ä¸»é¢˜
        now = get_time_func() if get_time_func else datetime.now()
        subject = f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type} - {now.strftime('%mæœˆ%dæ—¥ %H:%M')}"
        msg["Subject"] = Header(subject, "utf-8")

        # è®¾ç½®å…¶ä»–æ ‡å‡† header
        msg["MIME-Version"] = "1.0"
        msg["Date"] = formatdate(localtime=True)
        msg["Message-ID"] = make_msgid()

        # æ·»åŠ çº¯æ–‡æœ¬éƒ¨åˆ†ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        text_content = f"""
TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š
========================
æŠ¥å‘Šç±»å‹ï¼š{report_type}
ç”Ÿæˆæ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}

è¯·ä½¿ç”¨æ”¯æŒHTMLçš„é‚®ä»¶å®¢æˆ·ç«¯æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šå†…å®¹ã€‚
        """
        text_part = MIMEText(text_content, "plain", "utf-8")
        msg.attach(text_part)

        html_part = MIMEText(html_content, "html", "utf-8")
        msg.attach(html_part)

        print(f"æ­£åœ¨å‘é€é‚®ä»¶åˆ° {to_email}...")
        print(f"SMTP æœåŠ¡å™¨: {smtp_server}:{smtp_port}")
        print(f"å‘ä»¶äºº: {from_email}")

        try:
            if use_tls:
                # TLS æ¨¡å¼
                server = smtplib.SMTP(smtp_server, smtp_port, timeout=30)
                server.set_debuglevel(0)  # è®¾ä¸º1å¯ä»¥æŸ¥çœ‹è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                server.ehlo()
                server.starttls()
                server.ehlo()
            else:
                # SSL æ¨¡å¼
                server = smtplib.SMTP_SSL(smtp_server, smtp_port, timeout=30)
                server.set_debuglevel(0)
                server.ehlo()

            # ç™»å½•
            server.login(from_email, password)

            # å‘é€é‚®ä»¶
            server.send_message(msg)
            server.quit()

            print(f"é‚®ä»¶å‘é€æˆåŠŸ [{report_type}] -> {to_email}")
            return True

        except smtplib.SMTPServerDisconnected:
            print("é‚®ä»¶å‘é€å¤±è´¥ï¼šæœåŠ¡å™¨æ„å¤–æ–­å¼€è¿æ¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•")
            return False

    except smtplib.SMTPAuthenticationError as e:
        print("é‚®ä»¶å‘é€å¤±è´¥ï¼šè®¤è¯é”™è¯¯ï¼Œè¯·æ£€æŸ¥é‚®ç®±å’Œå¯†ç /æˆæƒç ")
        print(f"è¯¦ç»†é”™è¯¯: {str(e)}")
        return False
    except smtplib.SMTPRecipientsRefused as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæ”¶ä»¶äººåœ°å€è¢«æ‹’ç» {e}")
        return False
    except smtplib.SMTPSenderRefused as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šå‘ä»¶äººåœ°å€è¢«æ‹’ç» {e}")
        return False
    except smtplib.SMTPDataError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šé‚®ä»¶æ•°æ®é”™è¯¯ {e}")
        return False
    except smtplib.SMTPConnectError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ° SMTP æœåŠ¡å™¨ {smtp_server}:{smtp_port}")
        print(f"è¯¦ç»†é”™è¯¯: {str(e)}")
        return False
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ [{report_type}]ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False


def send_to_ntfy(
    server_url: str,
    topic: str,
    token: Optional[str],
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 3800,
    split_content_func: Callable = None,
) -> bool:
    """
    å‘é€åˆ° ntfyï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä¸¥æ ¼éµå®ˆ4KBé™åˆ¶ï¼‰

    Args:
        server_url: ntfy æœåŠ¡å™¨ URL
        topic: ntfy ä¸»é¢˜
        token: ntfy è®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    # æ—¥å¿—å‰ç¼€
    log_prefix = f"ntfy{account_label}" if account_label else "ntfy"

    # é¿å… HTTP header ç¼–ç é—®é¢˜
    report_type_en_map = {
        "å½“æ—¥æ±‡æ€»": "Daily Summary",
        "å½“å‰æ¦œå•æ±‡æ€»": "Current Ranking",
        "å¢é‡æ›´æ–°": "Incremental Update",
        "å®æ—¶å¢é‡": "Realtime Incremental",
        "å®æ—¶å½“å‰æ¦œå•": "Realtime Current Ranking",
    }
    report_type_en = report_type_en_map.get(report_type, "News Report")

    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Markdown": "yes",
        "Title": report_type_en,
        "Priority": "default",
        "Tags": "news",
    }

    if token:
        headers["Authorization"] = f"Bearer {token}"

    # æ„å»ºå®Œæ•´URLï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
    base_url = server_url.rstrip("/")
    if not base_url.startswith(("http://", "https://")):
        base_url = f"https://{base_url}"
    url = f"{base_url}/{topic}"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    header_reserve = get_max_batch_header_size("ntfy")
    batches = split_content_func(
        report_data, "ntfy", update_info, max_bytes=batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "ntfy", batch_size)

    total_batches = len(batches)
    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {total_batches} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # åè½¬æ‰¹æ¬¡é¡ºåºï¼Œä½¿å¾—åœ¨ntfyå®¢æˆ·ç«¯æ˜¾ç¤ºæ—¶é¡ºåºæ­£ç¡®
    # ntfyæ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯åœ¨ä¸Šé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æœ€åä¸€æ‰¹å¼€å§‹æ¨é€
    reversed_batches = list(reversed(batches))

    print(f"{log_prefix}å°†æŒ‰åå‘é¡ºåºæ¨é€ï¼ˆæœ€åæ‰¹æ¬¡å…ˆæ¨é€ï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ˜¾ç¤ºé¡ºåºæ­£ç¡®")

    # é€æ‰¹å‘é€ï¼ˆåå‘é¡ºåºï¼‰
    success_count = 0
    for idx, batch_content in enumerate(reversed_batches, 1):
        # è®¡ç®—æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼ˆç”¨æˆ·è§†è§’çš„ç¼–å·ï¼‰
        actual_batch_num = total_batches - idx + 1

        content_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆæ¨é€é¡ºåº: {idx}/{total_batches}ï¼‰ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        # æ£€æŸ¥æ¶ˆæ¯å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡4KB
        if content_size > 4096:
            print(f"è­¦å‘Šï¼š{log_prefix}ç¬¬ {actual_batch_num} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§ï¼ˆ{content_size} å­—èŠ‚ï¼‰ï¼Œå¯èƒ½è¢«æ‹’ç»")

        # æ›´æ–° headers çš„æ‰¹æ¬¡æ ‡è¯†
        current_headers = headers.copy()
        if total_batches > 1:
            current_headers["Title"] = f"{report_type_en} ({actual_batch_num}/{total_batches})"

        try:
            response = requests.post(
                url,
                headers=current_headers,
                data=batch_content.encode("utf-8"),
                proxies=proxies,
                timeout=30,
            )

            if response.status_code == 200:
                print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                success_count += 1
                if idx < total_batches:
                    # å…¬å…±æœåŠ¡å™¨å»ºè®® 2-3 ç§’ï¼Œè‡ªæ‰˜ç®¡å¯ä»¥æ›´çŸ­
                    interval = 2 if "ntfy.sh" in server_url else 1
                    time.sleep(interval)
            elif response.status_code == 429:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é€Ÿç‡é™åˆ¶ [{report_type}]ï¼Œç­‰å¾…åé‡è¯•"
                )
                time.sleep(10)  # ç­‰å¾…10ç§’åé‡è¯•
                # é‡è¯•ä¸€æ¬¡
                retry_response = requests.post(
                    url,
                    headers=current_headers,
                    data=batch_content.encode("utf-8"),
                    proxies=proxies,
                    timeout=30,
                )
                if retry_response.status_code == 200:
                    print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é‡è¯•æˆåŠŸ [{report_type}]")
                    success_count += 1
                else:
                    print(
                        f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é‡è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{retry_response.status_code}"
                    )
            elif response.status_code == 413:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§è¢«æ‹’ç» [{report_type}]ï¼Œæ¶ˆæ¯å¤§å°ï¼š{content_size} å­—èŠ‚"
                )
            else:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                try:
                    print(f"é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
                except:
                    pass

        except requests.exceptions.ConnectTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ReadTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¯»å–è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ConnectionError as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥é”™è¯¯ [{report_type}]ï¼š{e}")
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¼‚å¸¸ [{report_type}]ï¼š{e}")

    # åˆ¤æ–­æ•´ä½“å‘é€æ˜¯å¦æˆåŠŸ
    if success_count == total_batches:
        print(f"{log_prefix}æ‰€æœ‰ {total_batches} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
        return True
    elif success_count > 0:
        print(f"{log_prefix}éƒ¨åˆ†å‘é€æˆåŠŸï¼š{success_count}/{total_batches} æ‰¹æ¬¡ [{report_type}]")
        return True  # éƒ¨åˆ†æˆåŠŸä¹Ÿè§†ä¸ºæˆåŠŸ
    else:
        print(f"{log_prefix}å‘é€å®Œå…¨å¤±è´¥ [{report_type}]")
        return False


def send_to_bark(
    bark_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 3600,
    batch_interval: float = 1.0,
    split_content_func: Callable = None,
) -> bool:
    """
    å‘é€åˆ° Barkï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä½¿ç”¨ markdown æ ¼å¼ï¼‰

    Args:
        bark_url: Bark URLï¼ˆåŒ…å« device_keyï¼‰
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        batch_interval: æ‰¹æ¬¡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    # æ—¥å¿—å‰ç¼€
    log_prefix = f"Bark{account_label}" if account_label else "Bark"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è§£æ Bark URLï¼Œæå– device_key å’Œ API ç«¯ç‚¹
    # Bark URL æ ¼å¼: https://api.day.app/device_key æˆ– https://bark.day.app/device_key
    parsed_url = urlparse(bark_url)
    device_key = parsed_url.path.strip('/').split('/')[0] if parsed_url.path else None

    if not device_key:
        print(f"{log_prefix} URL æ ¼å¼é”™è¯¯ï¼Œæ— æ³•æå– device_key: {bark_url}")
        return False

    # æ„å»ºæ­£ç¡®çš„ API ç«¯ç‚¹
    api_endpoint = f"{parsed_url.scheme}://{parsed_url.netloc}/push"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    header_reserve = get_max_batch_header_size("bark")
    batches = split_content_func(
        report_data, "bark", update_info, max_bytes=batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "bark", batch_size)

    total_batches = len(batches)
    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {total_batches} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # åè½¬æ‰¹æ¬¡é¡ºåºï¼Œä½¿å¾—åœ¨Barkå®¢æˆ·ç«¯æ˜¾ç¤ºæ—¶é¡ºåºæ­£ç¡®
    # Barkæ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯åœ¨ä¸Šé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æœ€åä¸€æ‰¹å¼€å§‹æ¨é€
    reversed_batches = list(reversed(batches))

    print(f"{log_prefix}å°†æŒ‰åå‘é¡ºåºæ¨é€ï¼ˆæœ€åæ‰¹æ¬¡å…ˆæ¨é€ï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ˜¾ç¤ºé¡ºåºæ­£ç¡®")

    # é€æ‰¹å‘é€ï¼ˆåå‘é¡ºåºï¼‰
    success_count = 0
    for idx, batch_content in enumerate(reversed_batches, 1):
        # è®¡ç®—æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼ˆç”¨æˆ·è§†è§’çš„ç¼–å·ï¼‰
        actual_batch_num = total_batches - idx + 1

        content_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆæ¨é€é¡ºåº: {idx}/{total_batches}ï¼‰ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        # æ£€æŸ¥æ¶ˆæ¯å¤§å°ï¼ˆBarkä½¿ç”¨APNsï¼Œé™åˆ¶4KBï¼‰
        if content_size > 4096:
            print(
                f"è­¦å‘Šï¼š{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§ï¼ˆ{content_size} å­—èŠ‚ï¼‰ï¼Œå¯èƒ½è¢«æ‹’ç»"
            )

        # æ„å»ºJSON payload
        payload = {
            "title": report_type,
            "markdown": batch_content,
            "device_key": device_key,
            "sound": "default",
            "group": "TrendRadar",
            "action": "none",  # ç‚¹å‡»æ¨é€è·³åˆ° APP ä¸å¼¹å‡ºå¼¹æ¡†,æ–¹ä¾¿é˜…è¯»
        }

        try:
            response = requests.post(
                api_endpoint,
                json=payload,
                proxies=proxies,
                timeout=30,
            )

            if response.status_code == 200:
                result = response.json()
                if result.get("code") == 200:
                    print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    success_count += 1
                    # æ‰¹æ¬¡é—´é—´éš”
                    if idx < total_batches:
                        time.sleep(batch_interval)
                else:
                    print(
                        f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                    )
            else:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                try:
                    print(f"é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
                except:
                    pass

        except requests.exceptions.ConnectTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ReadTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¯»å–è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ConnectionError as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥é”™è¯¯ [{report_type}]ï¼š{e}")
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¼‚å¸¸ [{report_type}]ï¼š{e}")

    # åˆ¤æ–­æ•´ä½“å‘é€æ˜¯å¦æˆåŠŸ
    if success_count == total_batches:
        print(f"{log_prefix}æ‰€æœ‰ {total_batches} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
        return True
    elif success_count > 0:
        print(f"{log_prefix}éƒ¨åˆ†å‘é€æˆåŠŸï¼š{success_count}/{total_batches} æ‰¹æ¬¡ [{report_type}]")
        return True  # éƒ¨åˆ†æˆåŠŸä¹Ÿè§†ä¸ºæˆåŠŸ
    else:
        print(f"{log_prefix}å‘é€å®Œå…¨å¤±è´¥ [{report_type}]")
        return False


def send_to_slack(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
    *,
    batch_size: int = 4000,
    batch_interval: float = 1.0,
    split_content_func: Callable = None,
) -> bool:
    """
    å‘é€åˆ° Slackï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä½¿ç”¨ mrkdwn æ ¼å¼ï¼‰

    Args:
        webhook_url: Slack Webhook URL
        report_data: æŠ¥å‘Šæ•°æ®
        report_type: æŠ¥å‘Šç±»å‹
        update_info: æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        proxy_url: ä»£ç† URLï¼ˆå¯é€‰ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily/current)
        account_label: è´¦å·æ ‡ç­¾ï¼ˆå¤šè´¦å·æ—¶æ˜¾ç¤ºï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        batch_interval: æ‰¹æ¬¡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°

    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"Slack{account_label}" if account_label else "Slack"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    header_reserve = get_max_batch_header_size("slack")
    batches = split_content_func(
        report_data, "slack", update_info, max_bytes=batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "slack", batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        # è½¬æ¢ Markdown åˆ° mrkdwn æ ¼å¼
        mrkdwn_content = convert_markdown_to_mrkdwn(batch_content)

        content_size = len(mrkdwn_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{content_size} å­—èŠ‚ [{report_type}]"
        )

        # æ„å»º Slack payloadï¼ˆä½¿ç”¨ç®€å•çš„ text å­—æ®µï¼Œæ”¯æŒ mrkdwnï¼‰
        payload = {"text": mrkdwn_content}

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )

            # Slack Incoming Webhooks æˆåŠŸæ—¶è¿”å› "ok" æ–‡æœ¬
            if response.status_code == 200 and response.text == "ok":
                print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                # æ‰¹æ¬¡é—´é—´éš”
                if i < len(batches):
                    time.sleep(batch_interval)
            else:
                error_msg = response.text if response.text else f"çŠ¶æ€ç ï¼š{response.status_code}"
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{error_msg}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True
