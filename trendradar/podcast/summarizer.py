# coding=utf-8
"""
AI æ‘˜è¦ç”Ÿæˆæ¨¡å— (News Summarizer Module)

å°†æ‹‰å–åˆ°çš„æ–°é—»æ­£æ–‡æŒ‰å…³é”®è¯èšåˆåï¼Œç”Ÿæˆé€‚åˆæ’­å®¢æœ—è¯»çš„æ‘˜è¦æ–‡æœ¬ã€‚
è¯¥æ¨¡å—é¢„ç•™äº†å¤šç§ LLM æœåŠ¡æ¥å£ï¼Œå¯æ ¹æ®é…ç½®é€‰æ‹©ä¸åŒçš„æä¾›å•†ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    summarizer = NewsSummarizer(config)
    summary = summarizer.summarize("AI", articles_content)
"""

import os
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, List, Optional

import requests


@dataclass
class SummaryResult:
    """
    æ‘˜è¦ç”Ÿæˆç»“æœæ•°æ®ç±»
    
    Attributes:
        keyword: å…³é”®è¯
        summary: ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬ï¼ˆé€‚åˆæ’­å®¢æœ—è¯»ï¼‰
        article_count: å‚ä¸æ€»ç»“çš„æ–‡ç« æ•°é‡
        success: æ˜¯å¦æˆåŠŸ
        error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
        tokens_used: æ¶ˆè€—çš„ token æ•°é‡
    """
    keyword: str
    summary: str = ""
    article_count: int = 0
    success: bool = False
    error: str = ""
    tokens_used: int = 0


class BaseSummarizer(ABC):
    """
    æ‘˜è¦ç”Ÿæˆå™¨åŸºç±»
    
    å®šä¹‰æ‘˜è¦ç”Ÿæˆçš„æ ‡å‡†æ¥å£ï¼Œä¸åŒçš„ LLM æœåŠ¡å®ç°æ­¤åŸºç±»ã€‚
    """
    
    @abstractmethod
    def summarize(
        self,
        keyword: str,
        articles: List[Dict],
    ) -> SummaryResult:
        """
        ç”Ÿæˆå…³é”®è¯ç›¸å…³æ–°é—»çš„æ‘˜è¦
        
        Args:
            keyword: å…³é”®è¯/è¯ç»„
            articles: æ–‡ç« åˆ—è¡¨ï¼Œæ¯ç¯‡åŒ…å« title, content ç­‰å­—æ®µ
            
        Returns:
            SummaryResult: æ‘˜è¦ç»“æœ
        """
        pass


class NewsSummarizer(BaseSummarizer):
    """
    æ–°é—»æ‘˜è¦ç”Ÿæˆå™¨
    
    å°†å¤šç¯‡æ–°é—»æ–‡ç« å†…å®¹åˆå¹¶ï¼Œç”Ÿæˆé€‚åˆæ’­å®¢æœ—è¯»çš„æ‘˜è¦ã€‚
    æ”¯æŒå¤šç§ LLM æœåŠ¡æä¾›å•†ï¼ˆé€šè¿‡é…ç½®åˆ‡æ¢ï¼‰ã€‚
    
    Attributes:
        provider: LLM æœåŠ¡æä¾›å•†ï¼ˆopenai/302ai/otherï¼‰
        api_key: API å¯†é’¥
        model: æ¨¡å‹åç§°
        api_url: API ç«¯ç‚¹
    """
    
    # é¢„è®¾çš„ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿ï¼ˆç”Ÿæˆæ’­å®¢é£æ ¼çš„æ‘˜è¦ï¼‰
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–°é—»æ’­å®¢ä¸»æŒäººã€‚è¯·æ ¹æ®æä¾›çš„æ–°é—»å†…å®¹ï¼Œç”Ÿæˆä¸€æ®µé€‚åˆæ’­å®¢æœ—è¯»çš„æ‘˜è¦ã€‚

è¦æ±‚ï¼š
1. è¯­è¨€æµç•…è‡ªç„¶ï¼Œé€‚åˆå£è¯­æœ—è¯»
2. æ—¶é•¿æ§åˆ¶åœ¨ 30-60 ç§’å·¦å³ï¼ˆçº¦ 100-200 å­—ï¼‰
3. çªå‡ºå…³é”®ä¿¡æ¯å’Œçƒ­ç‚¹è¦ç‚¹
4. é¿å…ä½¿ç”¨éš¾ä»¥æœ—è¯»çš„ç¬¦å·å’Œæ•°å­—
5. ä»¥ã€Œå…³äº{keyword}çš„çƒ­ç‚¹èµ„è®¯ã€å¼€å¤´
6. ç”¨ç®€æ´æœ‰åŠ›çš„è¯­è¨€ç»“æŸ

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚"""

    # ç”¨æˆ·æç¤ºè¯æ¨¡æ¿
    USER_PROMPT_TEMPLATE = """å…³é”®è¯ï¼š{keyword}

ç›¸å…³æ–°é—»å†…å®¹ï¼š
{articles_content}

è¯·ç”Ÿæˆé€‚åˆæ’­å®¢æœ—è¯»çš„æ‘˜è¦ã€‚"""
    
    def __init__(
        self,
        provider: str = "",
        api_key: Optional[str] = None,
        model: str = "",
        api_url: Optional[str] = None,
        proxy_url: Optional[str] = None,
        max_content_length: int = 4000,
    ):
        """
        åˆå§‹åŒ–æ‘˜è¦ç”Ÿæˆå™¨
        
        Args:
            provider: LLM æœåŠ¡æä¾›å•†ï¼ˆopenai/302ai/otherï¼‰
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
            api_url: API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰
            proxy_url: ä»£ç†æœåŠ¡å™¨ URLï¼ˆå¯é€‰ï¼‰
            max_content_length: æ¯ç¯‡æ–‡ç« æœ€å¤§å†…å®¹é•¿åº¦
        """
        self.provider = provider.lower() if provider else ""
        self.api_key = api_key or ""
        self.model = model or ""
        self.api_url = api_url or ""
        self.proxy_url = proxy_url
        self.max_content_length = max_content_length
        
        # æ ¹æ® provider è®¾ç½®é»˜è®¤å€¼
        self._setup_provider_defaults()
    
    def _setup_provider_defaults(self):
        """æ ¹æ® provider è®¾ç½®é»˜è®¤çš„ API ç«¯ç‚¹å’Œæ¨¡å‹"""
        if self.provider == "openai":
            self.api_url = self.api_url or "https://api.openai.com/v1/chat/completions"
            self.model = self.model or "gpt-4o-mini"
            self.api_key = self.api_key or os.environ.get("OPENAI_API_KEY", "")
        elif self.provider == "deepseek":
            # DeepSeek å®˜æ–¹ APIï¼ˆOpenAI å…¼å®¹ï¼‰
            self.api_url = self.api_url or "https://api.deepseek.com/chat/completions"
            self.model = self.model or "deepseek-chat"
            self.api_key = self.api_key or os.environ.get("DEEPSEEK_API_KEY", "")
        elif self.provider == "302ai":
            # 302.AI ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
            self.api_url = self.api_url or "https://api.302.ai/v1/chat/completions"
            self.model = self.model or "gpt-4o-mini"
            self.api_key = self.api_key or os.environ.get("AI302_API_KEY", "")
        # å…¶ä»– provider éœ€è¦ç”¨æˆ·æä¾›å®Œæ•´é…ç½®
    
    def _prepare_articles_content(self, articles: List[Dict]) -> str:
        """
        å‡†å¤‡æ–‡ç« å†…å®¹æ–‡æœ¬
        
        å°†å¤šç¯‡æ–‡ç« çš„å†…å®¹åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æœ¬ï¼Œç”¨äº LLM è¾“å…¥ã€‚
        
        Args:
            articles: æ–‡ç« åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„æ–‡ç« å†…å®¹æ–‡æœ¬
        """
        content_parts = []
        
        for i, article in enumerate(articles, 1):
            title = article.get("title", "æ— æ ‡é¢˜")
            content = article.get("content", "")
            
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(content) > self.max_content_length:
                content = content[:self.max_content_length] + "..."
            
            content_parts.append(f"ã€æ–°é—» {i}ã€‘{title}\n{content}")
        
        return "\n\n".join(content_parts)
    
    def summarize(
        self,
        keyword: str,
        articles: List[Dict],
    ) -> SummaryResult:
        """
        ç”Ÿæˆå…³é”®è¯ç›¸å…³æ–°é—»çš„æ‘˜è¦
        
        Args:
            keyword: å…³é”®è¯/è¯ç»„
            articles: æ–‡ç« åˆ—è¡¨ï¼Œæ¯ç¯‡åŒ…å« title, content ç­‰å­—æ®µ
            
        Returns:
            SummaryResult: æ‘˜è¦ç»“æœ
        """
        # æ£€æŸ¥é…ç½®
        if not self.provider:
            return SummaryResult(
                keyword=keyword,
                success=False,
                error="æœªé…ç½® LLM æœåŠ¡æä¾›å•†ï¼ˆproviderï¼‰"
            )
        
        if not self.api_key:
            return SummaryResult(
                keyword=keyword,
                success=False,
                error=f"æœªé…ç½® {self.provider.upper()} API å¯†é’¥"
            )
        
        if not articles:
            return SummaryResult(
                keyword=keyword,
                success=False,
                error="æ²¡æœ‰å¯ç”¨çš„æ–‡ç« å†…å®¹"
            )
        
        # å‡†å¤‡å†…å®¹
        articles_content = self._prepare_articles_content(articles)
        
        # æ„å»ºæç¤ºè¯
        system_prompt = self.SYSTEM_PROMPT.format(keyword=keyword)
        user_prompt = self.USER_PROMPT_TEMPLATE.format(
            keyword=keyword,
            articles_content=articles_content
        )
        
        # è°ƒç”¨ LLM API
        try:
            result = self._call_llm_api(system_prompt, user_prompt)
            
            return SummaryResult(
                keyword=keyword,
                summary=result.get("content", ""),
                article_count=len(articles),
                success=True,
                tokens_used=result.get("tokens", 0)
            )
            
        except Exception as e:
            return SummaryResult(
                keyword=keyword,
                article_count=len(articles),
                success=False,
                error=str(e)
            )
    
    def _call_llm_api(
        self,
        system_prompt: str,
        user_prompt: str,
    ) -> Dict:
        """
        è°ƒç”¨ LLM APIï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯
            
        Returns:
            Dict: åŒ…å« content å’Œ tokens çš„ç»“æœå­—å…¸
        """
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            "temperature": 0.7,
            "max_tokens": 500,
        }
        
        # é…ç½®ä»£ç†
        proxies = None
        if self.proxy_url:
            proxies = {"http": self.proxy_url, "https": self.proxy_url}
        
        response = requests.post(
            self.api_url,
            headers=headers,
            json=payload,
            proxies=proxies,
            timeout=60,
        )
        
        response.raise_for_status()
        result = response.json()
        
        # è§£æå“åº”ï¼ˆOpenAI æ ¼å¼ï¼‰
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        tokens = result.get("usage", {}).get("total_tokens", 0)
        
        return {"content": content, "tokens": tokens}
    
    def summarize_batch(
        self,
        keyword_articles: Dict[str, List[Dict]],
    ) -> Dict[str, SummaryResult]:
        """
        æ‰¹é‡ç”Ÿæˆå¤šä¸ªå…³é”®è¯çš„æ‘˜è¦
        
        Args:
            keyword_articles: å…³é”®è¯åˆ°æ–‡ç« åˆ—è¡¨çš„æ˜ å°„
            
        Returns:
            Dict[str, SummaryResult]: å…³é”®è¯åˆ°æ‘˜è¦ç»“æœçš„æ˜ å°„
        """
        results = {}
        total = len(keyword_articles)
        
        print(f"ğŸ“ å¼€å§‹ç”Ÿæˆæ‘˜è¦ï¼Œå…± {total} ä¸ªå…³é”®è¯")
        
        for i, (keyword, articles) in enumerate(keyword_articles.items(), 1):
            print(f"  [{i}/{total}] æ­£åœ¨æ€»ç»“ã€Œ{keyword}ã€...")
            
            result = self.summarize(keyword, articles)
            results[keyword] = result
            
            if result.success:
                print(f"    âœ… æˆåŠŸï¼Œæ‘˜è¦é•¿åº¦: {len(result.summary)} å­—ç¬¦")
            else:
                print(f"    âŒ å¤±è´¥: {result.error}")
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results.values() if r.success)
        print(f"ğŸ“Š æ‘˜è¦å®Œæˆ: {success_count}/{total} æˆåŠŸ")
        
        return results
